<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://dev-owner.github.io/blog/</id>
    <title>dev-owner's blog Blog</title>
    <updated>2022-11-20T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://dev-owner.github.io/blog/"/>
    <subtitle>dev-owner's blog Blog</subtitle>
    <icon>https://dev-owner.github.io/blog/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Amazon EKS on Kafka vs MSK]]></title>
        <id>aws-eks-on-kafka-vs-msk</id>
        <link href="https://dev-owner.github.io/blog/aws-eks-on-kafka-vs-msk"/>
        <updated>2022-11-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[aws eks on kafka vs msk]]></summary>
        <content type="html"><![CDATA[<p>Kafka는 이벤트 기반 아키텍처나 MSA 등등 현대 아키텍처 메세지 브로커로 빼놓을 수 없는 요소입니다.</p><p>EKS 또한 대부분의 애플리케이션을 컨테이너로 배포하는 와중에 거의 필수적으로 사용하는 쿠버네티스를 보다 더 편리하게 사용할 때 많이 사용하는 요소입니다.</p><p>그러면 Kafka를 EKS에 올려서 사용하는 케이스에 대해 어떤 방법이 있는지, 장단점이 무엇인지 알아봅시다.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="어떤-방법들이-있을까">어떤 방법들이 있을까?<a class="hash-link" href="#어떤-방법들이-있을까" title="제목으로 바로 가기">​</a></h2><p>EKS(K8S)에 카프카를 배포하는 방식에는 여러가지가 있을 것 같습니다.</p><ol><li><a href="https://github.com/strimzi/strimzi-kafka-operator" target="_blank" rel="noopener noreferrer">Manage Kafka on Kubernetes: Strimzi</a></li><li><a href="https://github.com/banzaicloud/koperator" target="_blank" rel="noopener noreferrer">Banzai Cloud</a></li><li><a href="https://docs.confluent.io/operator/current/co-deploy-cfk.html" target="_blank" rel="noopener noreferrer">Confluent</a></li><li><a href="https://artifacthub.io/packages/helm/bitnami/kafka" target="_blank" rel="noopener noreferrer">Bitnami Kafka Helm chart</a></li></ol><p>위 방식들 말고도 여러 방법들이 있을 수 있습니다 :)</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="eks-on-kafka에서-생각해-볼-수-있는-점">EKS on Kafka에서 생각해 볼 수 있는 점<a class="hash-link" href="#eks-on-kafka에서-생각해-볼-수-있는-점" title="제목으로 바로 가기">​</a></h2><p>아무래도 직접 클러스터를 관리하다 보니 그 과정에서 배우는건 많을 것 같습니다. 그리고 모든것이 Admin의 통제 하에 관리되니 자유도나 디버깅 환경 또한 관리형 서비스보다는 편할 듯 싶습니다.</p><p>그러나 그 이외 부분에서는 제 지식의 한계인지 더 좋은점은 생각하지 못했습니다. 대부분의 케이스에서 heavy lifting한 작업을 대신해주는 관리형 서비스가 낫다는 생각을 떨칠수가 없네요..</p><p>구축하는 레퍼런스는 아래와 같은 사이트들이 있습니다.</p><ul><li><a href="https://medium.com/@JinnaBalu/kafka-cluster-on-amezon-eks-cluster-5850d67ae723" target="_blank" rel="noopener noreferrer">https://medium.com/@JinnaBalu/kafka-cluster-on-amezon-eks-cluster-5850d67ae723</a></li><li><a href="https://portworx.com/run-ha-kafka-amazon-elastic-container-service-kubernetes/" target="_blank" rel="noopener noreferrer">https://portworx.com/run-ha-kafka-amazon-elastic-container-service-kubernetes/</a></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="amazon-managed-streaming-for-apache-kafkamsk">Amazon Managed Streaming for Apache Kafka(MSK)<a class="hash-link" href="#amazon-managed-streaming-for-apache-kafkamsk" title="제목으로 바로 가기">​</a></h2><p>AWS에서는 Kafka를 managed service로 제공하는 MSK가 있습니다.</p><p>위에서 잠깐 얘기했지만, 사실 대부분의 상황에서 MSK를 쓰는게 나을 것 같다는 생각입니다. 직접 설치 운영은 업데이트나 관리 측면에서 어려움을 겪을 확률이 크기 때문이고, Heavy lifting을 피할 수 있으면 피하는게 낫지 않을까라는 생각입니다.</p><p>그리고 관리 측면을 제외하더라도, EKS와 달리 MSK는 <strong>inter-az 데이터 전송 비용이 무료</strong>이기 때문에 이러한 부분또한 고려해보면 좋습니다.</p><h1>결론</h1><p>아무래도 요즘 대부분의 케이스에서 직접 클러스터를 구축해서 사용하는 것 보다는 관리형 서비스를 사용하는게 여러가지 측면에서 효율성이 좋은 것 같습니다. 단, 회사의 규모가 너무 커서 On-premise에 직접 클러스터를 구축해서 관리해야 하는 상황이나 회사의 상황에 맞춰 특정 기능을 커스터마이징 해야 하는 상황 같은 경우 직접 해야 할 수도 있다고 생각합니다.</p>]]></content>
        <author>
            <name>Jaewoo Sung</name>
            <uri>https://github.com/dev-owner</uri>
        </author>
        <category label="AWS" term="AWS"/>
        <category label="EKS" term="EKS"/>
        <category label="K8S" term="K8S"/>
        <category label="kubernetes" term="kubernetes"/>
        <category label="docker" term="docker"/>
        <category label="kafka" term="kafka"/>
        <category label="msk" term="msk"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[실리콘밸리에서 날아온 데이터 엔지니어링 컨퍼런스]]></title>
        <id>review-programmers-data-engineering-conference</id>
        <link href="https://dev-owner.github.io/blog/review-programmers-data-engineering-conference"/>
        <updated>2022-11-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[프로그래머스 실리콘밸리 데이터 엔지니어링 코스에서 주최한 컨퍼런스 후기]]></summary>
        <content type="html"><![CDATA[<h3 class="anchor anchorWithStickyNavbar_LWe7" id="배경">배경<a class="hash-link" href="#배경" title="제목으로 바로 가기">​</a></h3><p>제가 처음 <a href="https://school.programmers.co.kr/learn/courses/14982" target="_blank" rel="noopener noreferrer">실리콘밸리에서 날아온 데이터 엔지니어링 코스</a>를 알게 된 건 아래 Youtube EO Channel에 올라온 한기용님 영상을 시청한 이후 입니다. 총 3부까지 있는 이 영상을 보고 나서 여러가지로 많은 생각을 하게 되었습니다. 혹시 아직 안보셨다면 한번쯤 가볍게 시청해보시는 것도 추천 드립니다.</p><p><img loading="lazy" src="/blog/assets/images/2022-11-10-1-c9a1a06bca769dd736fa5a910997c01e.png" width="2250" height="1314" class="img_ev3q"></p><p>기존에 4년정도 데이터 엔지니어링 업무를 대기업에서 했었는데, 다른 곳에서는 어떻게 하고 있는지 궁금하기도 하고 내가 기존에 몰랐던 것들을 혹시 배울 수 있지 않을까 하여 코스를 신청하게 되었습니다. 듣고 보니 역시 기대를 저버리지 않고 강의가 나름 알차게 코스가 구성되어 있어 많은 걸 배울 수 있었던 것 같습니다. 역시 세상은 넓고 배울것은 많습니다 :)</p><p>이 코스는 2022년 10월 기준 벌써 10기를 운영할 만큼 관련 종사자분들이 많이 듣고 계시기도 한데 이번에 코스 수강생들 대상으로 기용님이 데이터 엔지니어링 <a href="https://school.programmers.co.kr/learn/courses/15230" target="_blank" rel="noopener noreferrer">컨퍼런스를</a> 열어주셔서 다녀온 후기를 작성해보려 합니다.</p><p><img loading="lazy" src="/blog/assets/images/2022-11-10-2-20c06d0595f680eaabc7a0eca90878c7.png" width="1310" height="1250" class="img_ev3q">
(출처 : <a href="https://www.linkedin.com/in/hannahhejang/" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/in/hannahhejang/</a>)</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="목차">목차<a class="hash-link" href="#목차" title="제목으로 바로 가기">​</a></h3><p>금일 컨퍼런스 목차입니다.</p><ol><li>Airflow 환경 고도화하기 (<a href="https://www.linkedin.com/in/ACoAAB0dV2QBZEoHPDMHVUaWR3F-okOKbAsuqhQ" target="_blank" rel="noopener noreferrer">hoyeon lee</a>)</li><li>공공데이터 적재하기 (<a href="https://www.linkedin.com/in/ACoAADdQHFoBvXqcwhKQG5YBRI0MNzRqGv_9j7w" target="_blank" rel="noopener noreferrer">Eunji Yi</a>)</li><li>스타트업에서 데이터기반 의사결정 구조 만들기 (<a href="https://www.linkedin.com/in/ACoAAAJgCuMBC6ob4tTNYE290unr86fVRLD7blM" target="_blank" rel="noopener noreferrer">Minjong Kim</a>)</li><li>참석자 네트워킹</li></ol><p>비록 시간대가 퇴근 후 저녁시간대였지만 1번부터 3번까지 흥미로운 주제로 가득했고 이는 컨퍼런스에 참가할 충분한 동기부여가 되었습니다. 참석자간 네트워킹 시간 같은 경우, 제가 한번도 경험이 없기 때문에 사실 한국 특성상 서먹서먹하고 어색한 분위기가 흐르다가 끝나지 않을까 막연한 예상을 하고 일단 들어갔습니다.</p><p><img loading="lazy" src="/blog/assets/images/2022-11-10-3-fe3ad1315de62c2c29f7ed0135f18c71.png" width="1202" height="1096" class="img_ev3q">
(출처 : <a href="https://www.linkedin.com/in/hannahhejang/" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/in/hannahhejang/</a>)</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="airflow-환경-고도화하기">Airflow 환경 고도화하기<a class="hash-link" href="#airflow-환경-고도화하기" title="제목으로 바로 가기">​</a></h3><p>금일 컨퍼런스 첫번째 세션입니다. 쏘카의 <a href="https://www.linkedin.com/in/ACoAAB0dV2QBZEoHPDMHVUaWR3F-okOKbAsuqhQ" target="_blank" rel="noopener noreferrer">Grab</a>님이 발표를 진행해 주셨습니다.</p><p>GKE에서 K8S에 Airflow를 운영중이셨고, 통합 저장소로 BigQuery를 사용중이셨습니다. Airflow는 외부 저장소에서 BigQuery로 데이터를 적재할때 Batch 작업을 하기 위해 주로 사용했네요.</p><p>Airflow 개발환경에 대한 이야기를 많이 말씀 해주셨습니다. 초기 아키텍처는 Git과 연계하여 DAG 버전관리와 동시에 Airflow에 배포되는 구조를 가져간 것 같구요. 운영환경 및 다른 동료들과 독립적인 환경을 구축하기 위해 Git Branch를 따로 가져가고 push되면 buddyworks, argocd를 통해 전용 airflow가 생성되어 테스트 및 검증 후 운영 merge되는 구조였다고 합니다.</p><p>이런 구조에서 발생했던 자원 낭비, 불편한 환경, 긴 피드백 루프등의 많은 이슈로 인해 개발 환경 파이프라인을 docker compose 기반 로컬 노트북 환경으로 개선을 했다고 합니다. GCP Service Account를 통합 인증 수단으로 활용하였고, DAG Parsing Optimization을 위해 .airflowignore를 적극적으로 활용하셨다고 해요.</p><p>이러한 개선 구조를 통해 클러스터를 띄우는 시간을 많이 단축시키고 피드백 루프를 단축시켜 생산성을 많이 향상시킬 수 있었다고 합니다.</p><p>이어서 테스트 환경에 대한 이야기가 나왔는데, DAG 기본 문법 등을 체크하기 위해 pytest를 활용하셨고, pre commit hook을 사용하셨다고 합니다. Github Action에서 컨벤션, 테스트, 검증 등을 추가로 진행했다고 하네요.</p><p>꿀팁들도 여러가지 소개해 주셨는데, 그 중에 CleanUp DAG를 만들어서 주기적으로 TI나 DagRun등의 정보를 삭제하여 전반적인 cluster 반응성 등을 향상시킨 점이 인상깊었습니다.</p><p>모니터링, DAG 운영 알람, 보안 및 RBAC 적용, 외부 접속 정보에 대한 secret 저장소 활용, gcp secret manager 적용 등 많은 내용을 얘기해 주셨지만 시간이 많지는 않은 관계로 깊이는 다루지 못했던것 같습니다.</p><p>이후 위 내용들을 포함한 전반적인 내용을 <a href="https://tech.socarcorp.kr/data/2022/11/09/advanced-airflow-for-databiz.html" target="_blank" rel="noopener noreferrer">SOCAR Tech Blog</a>에서 소개해 주셔서 관심있으시면 한번 보시는걸 추천 드립니다.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="공공데이터-적재하기">공공데이터 적재하기<a class="hash-link" href="#공공데이터-적재하기" title="제목으로 바로 가기">​</a></h3><p>공공데이터 적재관련해서는 뱅크샐러드의 <a href="https://www.linkedin.com/in/ACoAADdQHFoBvXqcwhKQG5YBRI0MNzRqGv_9j7w" target="_blank" rel="noopener noreferrer">Eunji Yi</a>님이 발표해주셨는데요, 처음 소개에서 NASA에서 일한 경력이 있으신게 아주 인상깊었습니다.</p><p>이후에 뱅크샐러드에서 공공데이터 수집 관련해서 고군분투기를 말씀해 주셨는데, 본격적으로 공공데이터를 사용하기 위해 고려해야 할 것들이 얼마나 많은지 알 수 있었습니다.</p><p>저는 이전에 한번 업무에서 공공데이터 수집을 해봤는데도 불구하고, 제대로 여러기관의 데이터를 사용하기 위해 필요한것들을 이번에 처음 알았는데요, 대표적으로 기억나는 어려운 점들은 아래와 같았습니다.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">1. 정의가 같은 컬럼이라도, 발행하는 기관이나 API에 따라 이름이 다를 수 있다.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Enum으로 관리되어야 할 것 같은 상수값들이 역시 기관이나 API에 따라 이름이 다를 수 있다.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. API명세가 아닌 2번과 같은 값 같은 경우는 내용이 언제 바뀔지 모른다.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. 값이 기관에서만 알아볼 수 있는 특정 코드로 되어있는 경우가 대다수이다.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. 4번과 같은 코드는 해당 API를 제공하는 곳이 아니라 저 멀리 이상한 다른 기관 사이트의 깊숙히 숨겨진 어딘가에 있다.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">6. 공공기관에 문의는 한세월이다.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="클립보드에 코드 복사" title="복사" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>뱅크샐러드에서는 위의 1번~6번을 해결하기 위해 중간 Layer를 두어 잘 추상화하여 사용하고 계신다고 하였습니다.</p><p>사실 이런 부분이 실제 데이터를 본격적으로 사용하고자 할 때 크나큰 어려움을 겪는 부분이죠.
이런 데이터 표준과 같은 내용은 이미 제공하는 측에서 관리하여 이용자가 편하게 이용할 수 있게끔 관리해야 한다고 생각합니다. (많은 기관에서 데이터를 open하고 있는것은 아주 긍정적이지만, 아직 갈길이 먼 것 같습니다)</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="스타트업에서-데이터기반-의사결정-구조-만들기">스타트업에서 데이터기반 의사결정 구조 만들기<a class="hash-link" href="#스타트업에서-데이터기반-의사결정-구조-만들기" title="제목으로 바로 가기">​</a></h3><p>마지막 세션은 NOUL의 <a href="https://www.linkedin.com/in/ACoAAAJgCuMBC6ob4tTNYE290unr86fVRLD7blM" target="_blank" rel="noopener noreferrer">Minjong Kim</a>님이 발표해주셨습니다.</p><p>스타트업에서 어떤 문제를 발견하고, 해당 문제를 그냥 지나치지 않고 데이터를 기반으로 의사결정하여 개선해나가는 과정을 말씀해 주셨습니다.
일을 하다 보니 데이터가 동료들이 작업하고 있는 환경의 데이터가 여기저기 파편화 되어 있고, 버전이 맞지 않으며 이로인해 비즈니스 임팩트까지 발생하는 것을 파악하셨고, 주 업무 분야가 아님에도 불구하고 이런것을 개선하기 위해 아래와 같은 과정을 진행하셨다고 합니다.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">1. NAS, Google Spreadsheet 기반 파일 사용 추적 후 DB에 정규화하여 데이터 사용 및 정합성 측면 개선</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. ML 모델 평가 추론 환경 개선</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. S3 + Sagemaker + DB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Inference를 반복적으로 수행하지 않게 개선</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. 통일되지 않은 데이터 타입, 변수명 등 전수조사 및 통일</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">6. 이러한 작업을 통한 데이터 가시성 확보</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="클립보드에 코드 복사" title="복사" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>사실 데이터쪽 업무를 하시는 분들이라면 아시겠지만, 당연히 필요한 일을 여러가지 이유로 하지 못하는 경우가 많습니다. 위의 사례를 통해 문제점 발견부터 의사결정권자와 동료들을 설득하는 과정, 개선하는 작업, 이후 시각화를 통한 추가 개선 사항 도출까지 많은 부분을 배운 것 같습니다.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="네트워킹">네트워킹<a class="hash-link" href="#네트워킹" title="제목으로 바로 가기">​</a></h3><p>네트워킹 같은 경우 사람이 50명 가량 되어 여러 팀으로 나누어 진행하였습니다. 팀마다 발표하신 연사분들이 10분씩 돌아가며 질답을 받아주시고, 중간중간 자유롭게 주변 사람들하고 네트워킹 하는 시간을 가졌는데, 서먹할 것이라는 예상과 다르게 다들 엄청 적극적으로 네트워킹을 하셨던 것 같습니다. (순간 여기가 한국이 맞나 생각이 들었습니다 ^^;) 덕분에 소심한 저도 조금씩 질문도 하고 명함도 주고받고 했던 것 같네요.</p><p>아래는 제가 주로 질문했던 질문입니다.</p><ol><li><p>(Grab님에게) Socar에서 airflow dev 환경 구성할 때 Dev용 DW는 어떻게 구성하는지?</p><ul><li>(답변) Dev용 DW가 따로 있고 Test를 하는 사람이 데이터를 그때마다 임의로 구성하여 테스트</li><li>제가 궁금했던건 데이터가 다른 데이터를 복잡하게 의존하는 경우가 많아서 그런 경우 기존 DW와 비슷하게 구성해야 하는 경우가 있고 결국 효율성을 위해 운영환경과 비슷하게 구성해야 하는 경우가 많은데, 어떻게 하고있는지 궁금해서 여쭤봤습니다. 역시 운영환경과 비슷하게 하는건 리소스의 문제가 있기 때문에 작업자가 약간 힘들더라도 개별로 데이터를 구성하여 테스트를 한다고 하네요.</li></ul></li><li><p>(Grab님에게) BigQuery의 장점?</p><ul><li>(답변) 대충 넣어도 사용하기 편하고, 성능이 좋다. 비용은 모르겠다.</li><li>대충 넣어도 사용하기 편한건 제가 직접 경험해보지 않아 모르겠지만 성능은 AWS Redshift Serverless와 별 차이 없는게 벤치마크로 확인되어 인식의 차이가 아닌가 싶습니다. 비용도 AWS 대비 BigQuery가 비싼 케이스가 많은 것 같은데 사용 편의성에 묻혀서 많은 고객들이 그냥 사용하는 것 같기도 하네요.</li></ul></li><li><p>(이은지님에게) 공공데이터용 중간 Layer를 오픈소스로 공개하실 생각은 없는지?</p><ul><li>(답변) 회사 정책에 따라 확인해보겠다.</li><li>회사 자산이니 당연히 안될거라 생각하긴 했습니다..ㅎㅎ</li></ul></li></ol><p>여러 스타트업, 중견기업, 대기업에 다니시는분들이 골고루 계셨던 것 같고 취업준비생 분들도 간혹 계셨던 것 같습니다. 평소에 자주 쓰던 앱을 개발한 회사에서 오신분들을 보니 신기하기도 하고 짧지만 궁금했던 것들을 물어보며 그들의 생각도 조금이나마 들어볼 수 있던 좋은 시간이었습니다.</p><p>네트워킹을 1시간이나 잡아서 너무 많은 시간을 잡은 것 아닌가라는 생각을 했었는데, 마지막에는 다들 시간이 모자라서 허겁지겁 명함만 교환하고 아쉽게 헤어졌던 것 같네요.</p>]]></content>
        <author>
            <name>Jaewoo Sung</name>
            <uri>https://github.com/dev-owner</uri>
        </author>
        <category label="data" term="data"/>
        <category label="data engineering" term="data engineering"/>
        <category label="airflow" term="airflow"/>
        <category label="공공 데이터" term="공공 데이터"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[2022 Socar data meetup]]></title>
        <id>2022-socar-data-meet-up</id>
        <link href="https://dev-owner.github.io/blog/2022-socar-data-meet-up"/>
        <updated>2022-10-27T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[2022 socar data meetup review]]></summary>
        <content type="html"><![CDATA[<p>어느날, 링크드인 피드를 둘러보던 중 관심이 가는 <a href="https://www.linkedin.com/feed/update/urn:li:activity:6986550988979539968/?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A6986550988979539968%29" target="_blank" rel="noopener noreferrer">글</a>을 보았습니다. 바로 2022 쏘카 데이터 밋업인데요, 이전에 <a href="https://dev-owner.github.io/blog/review-programmers-data-engineering-conference" target="_blank" rel="noopener noreferrer">데이터 엔지니어링 컨퍼런스</a>를 다녀온 후로 이런 오프라인 밋업에 대한 이미지가 좋아져서 바로 등록 신청 했습니다.</p><p><img loading="lazy" alt="socar-meetup" src="/blog/assets/images/2022-10-27-1-ea5c6f68b5bb32dfdd24cb7fedb00af1.png" width="1266" height="948" class="img_ev3q"></p><p>발표 주제는 아래와 같았습니다.</p><ol><li>무려 2만대의 차량을 AI로 관리하는 방법</li><li>데이터로 비즈니스 급속 성장 부스터 달기</li><li>데이터로 고객경험 개선하기</li><li>기술로 쏘카의 핵심 비즈니스 문제 해결하기</li></ol><p><img loading="lazy" src="/blog/assets/images/2022-10-27-2-2f1c52609ace3f7b9f7b55d901a22153.png" width="1120" height="1138" class="img_ev3q"></p><p>조금 일찍 도착하여 먼저 도착하신분들과 쏘카에서 제공해준 간단한 저녁거리를 먹으며 담소를 나누었는데, 이번 밋업 경쟁률이 8:1이라는 소리를 듣고 꽤 놀랐습니다 :) 한편으로는 제가 너무도 운이 좋게 뽑혔구나 생각도 들었구요.</p><p>사실, 신청 당시에 바빠서 주제를 대충 보고 넘어갔다가 당일에 도착해서 대부분 <code>Data Science</code>쪽 관련 내용이라는것을 깨달았습니다. (필자는 Data Engineering쪽에 관심이 더 많았습니다..) 어쨌든 데이터쪽 분야 주제는 모두 흥미롭기 때문에 크게 실망하지 않고 세션 4개를 모두 잘 들었습니다.</p><p><img loading="lazy" src="/blog/assets/images/2022-10-27-3-6c7d40040294ca016350fcaf997ea9ad.png" width="1154" height="1178" class="img_ev3q"></p><p>세션들은 모두 재밌게 들었는데 포스팅 목적으로 간 것이 아니라 따로 기록을 하지 않아 세부적인 내용을 공유드릴 수가 없어서 아쉽습니다. 대략적인 느낌만 공유 드리자면 데이터 조직의 크기나 하고 있는 일들을 봤을 때, <code>이 회사 정말 데이터에 진심</code>이구나를 느꼈습니다. 비즈니스에서 풀어야 하는 문제들도 많은것 같고 그러한 문제들을 하나하나 데이터에 기반하여 잘 풀어나가는 것이 뭔가 이상적인 모습처럼 보였어요.</p><p><img loading="lazy" src="/blog/assets/images/2022-10-27-4-6c56c63ef4fd46a2a9c74deb626e4628.png" width="1158" height="1142" class="img_ev3q"></p><p>놀랐던것 중에 하나는 연사분들은 모두 팀장분들이셨는데 그 중 한분이 4년전 인턴으로 시작해서 지금 팀장역할을 하고 있는 모습이 정말 성과 위주로 사람을 평가한다고 느꼈습니다. 놀람 포인트가 하나 더 있는데, AI관련되어 Lab처럼 각종 유명 저널이나 컨퍼런스에 꾸준히 논문도 등록하고 있는것으로 보여서 그저 돈버는데만 집중하기보다 구성원들의 커리어와 업계에 기여를 하고있다는 느낌도 많이 받았습니다.</p><p><img loading="lazy" src="/blog/assets/images/2022-10-27-5-95ee45ddaf6fcd4e2fab1cf24ec3f348.png" width="1192" height="1198" class="img_ev3q"></p><p>세션이 다 끝나고, 쏘카측에서 발표 팀원분들과 직접적으로 Q&amp;A를 할 수 있는 방을 따로 잡아 시간을 마련해 주셨습니다. 개인적으로 다른분들과 네트워킹 시간이 따로 없어 아쉬운 부분이 있었지만 그래도 쏘카 구성원들과 만날 수 있어서 좋았습니다.</p><p>저는 죄송스럽게도 발표해주신 팀들보다 Data Engineering팀에 관심이 많았는데 마침 해당 팀도 방에서 Q&amp;A를 진행해 주셔서 운좋게 참석할 수 있었습니다.</p><p>들어가보니 제가 평소에 흥미롭게 읽었던 <a href="https://tech.socarcorp.kr/data/2022/07/25/analytics-engineering-with-dbt.html" target="_blank" rel="noopener noreferrer">데이터에 신뢰성과 재사용성까지, Analytics Engineering with dbt</a>글의 저자이신 험프리님이 해당 팀의 팀장 입장으로 계셔서 꽤나 놀랐습니다. 인사를 나누고, 제가 일하면서 궁금했던 점들을 몇가지 질문했는데 정말 시간이 금방 가더라구요. 다른분들 질문들도 재미있었고 정말 유익한 시간이었습니다.</p><p>이렇게 팀원분들과 미팅까지 끝나니 어느덧 10시가 넘어 집으로 가는데 같은 방에서 Q&amp;A를 하시던 분과 지하철역까지 걸어가면서 더 이야기를 할 정도로 다른 참석하신분들도 열정이 대단하셨던것 같습니다.</p><p>평소 밖을 나가지 않는 성격이라 이런 오프라인 밋업을 선호하지 않았는데 2회차 밋업도 좋은 인상으로 남아 앞으로 점점 더 많이 기웃거릴것 같네요!</p>]]></content>
        <author>
            <name>Jaewoo Sung</name>
            <uri>https://github.com/dev-owner</uri>
        </author>
        <category label="socar" term="socar"/>
        <category label="data" term="data"/>
        <category label="meetup" term="meetup"/>
    </entry>
</feed>